<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <title>
        NinetyOne&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/libs/highlight/styles/monokai-sublime.css">

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.1.0"></head>

<body id="bodyx">
    <div class="hd posts">
    <a href="/index.html"><i class="fa fa-reply replay-btn" aria-hidden="true"></i></a>
    <div class="post-title">
        <p>
            使用Gensim模块训练词向量(维基百科预料)
        </p>
        <hr>
    </div>
    <div class="post-content">
        <p>如果在以词为基本单元输入的自然语言处理任务中，都避免不了使用词的表示，词的表示有很多种，这里使用的是词向量，word2vec是目前比较通用的训练词向量的工具，使用Gensim模块，可以使词向量的训练变得简单，word2vec常见的两种模型 (CBOW和Skip-Gram) 他们的输入以及输出都是以单词为基本单位的，只是他们对应的输入以及输出不一样： </p>
<ol>
<li><p>Skip-Gram models：输入为单个词，输出目标为多个上下文单词；</p>
</li>
<li><p>CBOW models：输入为多个上下文单词，输出目标为一个单词；</p>
<p>从上面可以看出，无论是Skip-Gram models还是CBOW models基本的单元都是词，那么我们获取到的语料，必须要经过分词处理以后才能用于词向量的训练语料。 </p>
</li>
</ol>
<a id="more"></a>

<h5 id="1-数据的处理"><a href="#1-数据的处理" class="headerlink" title="1.数据的处理"></a>1.数据的处理</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.analyse</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> codecs</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="comment">#以写的方式打开原始的简体中文语料库</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">f=codecs.open(<span class="string">'zhwiki_jian_zh.txt'</span>,<span class="string">'r'</span>,encoding=<span class="string">"utf8"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="comment">#将分完词的语料写入到wiki_jian_zh_seg-189.5.txt文件中</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">target = codecs.open(<span class="string">"wiki_jian_zh_seg-189.5.txt"</span>, <span class="string">'w'</span>,encoding=<span class="string">"utf8"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">print(<span class="string">'open files'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">line_num=<span class="number">1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">line = f.readline()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line"><span class="comment">#循环遍历每一行，并对这一行进行分词操作</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果下一行没有内容的话，就会readline会返回-1，则while -1就会跳出循环</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> line:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">    print(<span class="string">'---- processing '</span>, line_num, <span class="string">' article----------------'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">    line_seg = <span class="string">" "</span>.join(jieba.cut(line))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">    target.writelines(line_seg)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">    line_num = line_num + <span class="number">1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">    line = f.readline()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line"><span class="comment">#关闭两个文件流，并退出程序</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">f.close()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line">target.close()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line">exit()</span></pre></td></tr></table></figure>

<h5 id="2-训练模型"><a href="#2-训练模型" class="headerlink" title="2.训练模型"></a>2.训练模型</h5><p>有了分好词的语料，我们就可以通过Gensim模块中的word2vec函数来训练语料</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os.path</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models.word2vec <span class="keyword">import</span> LineSentence</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"><span class="comment">#程序的入口</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.如果当前脚本文件做模块供其他程序使用的话，不会执行if __name__ == '__main__':中的内容</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"><span class="comment">#2.如果直接执行当前的额脚本文件的话，执行if __name__ == '__main__':中的内容</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#1.os.path.basename('g://tf/code') ==&gt;code</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#2.sys.argv[0]获取的是脚本文件的文件名称</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">    program = os.path.basename(sys.argv[<span class="number">0</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#指定name，返回一个名称为name的Logger实例</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">    logger = logging.getLogger(program)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#1.format: 指定输出的格式和内容，format可以输出很多有用信息，</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#%(asctime)s: 打印日志的时间</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#%(levelname)s: 打印日志级别名称</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#%(message)s: 打印日志信息</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s: %(levelname)s: %(message)s'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">    logging.root.setLevel(level=logging.INFO)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#打印这是一个通知日志</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line">    logger.info(<span class="string">"running %s"</span> % <span class="string">' '</span>.join(sys.argv))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line">    <span class="comment"># check and process input arguments</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">4</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line">        <span class="keyword">print</span> (globals()[<span class="string">'__doc__'</span>] % locals())</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">29</span></pre></td><td class="code"><pre><span class="line">        sys.exit(<span class="number">1</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">30</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#inp:分好词的文本</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">31</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#outp1:训练好的模型</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">32</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#outp2:得到的词向量</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">33</span></pre></td><td class="code"><pre><span class="line">    inp, outp1, outp2 = sys.argv[<span class="number">1</span>:<span class="number">4</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">34</span></pre></td><td class="code"><pre><span class="line">    <span class="string">'''</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">35</span></pre></td><td class="code"><pre><span class="line"><span class="string">    LineSentence(inp)：格式简单：一句话=一行; 单词已经过预处理并被空格分隔。</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">36</span></pre></td><td class="code"><pre><span class="line"><span class="string">    size：是每个词的向量维度； </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">37</span></pre></td><td class="code"><pre><span class="line"><span class="string">    window：是词向量训练时的上下文扫描窗口大小，窗口为5就是考虑前5个词和后5个词； </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">38</span></pre></td><td class="code"><pre><span class="line"><span class="string">    min-count：设置最低频率，默认是5，如果一个词语在文档中出现的次数小于5，那么就会丢弃； </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">39</span></pre></td><td class="code"><pre><span class="line"><span class="string">    workers：是训练的进程数（需要更精准的解释，请指正），默认是当前运行机器的处理器核数。这些参数先记住就可以了。</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">40</span></pre></td><td class="code"><pre><span class="line"><span class="string">    sg (&#123;0, 1&#125;, optional) – 模型的训练算法: 1: skip-gram; 0: CBOW</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">41</span></pre></td><td class="code"><pre><span class="line"><span class="string">    alpha (float, optional) – 初始学习率</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">42</span></pre></td><td class="code"><pre><span class="line"><span class="string">    iter (int, optional) – 迭代次数，默认为5</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">43</span></pre></td><td class="code"><pre><span class="line"><span class="string">    '''</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">44</span></pre></td><td class="code"><pre><span class="line">    model = Word2Vec(LineSentence(inp), size=<span class="number">400</span>, window=<span class="number">5</span>, min_count=<span class="number">5</span>, workers=multiprocessing.cpu_count())</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">45</span></pre></td><td class="code"><pre><span class="line">    model.save(outp1)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">46</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">#不以C语言可以解析的形式存储词向量</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">47</span></pre></td><td class="code"><pre><span class="line">    model.wv.save_word2vec_format(outp2, binary=<span class="literal">False</span>)</span></pre></td></tr></table></figure>

<p>这里有一些训练词向量的调参技巧：</p>
<ol>
<li>选择的训练word2vec的语料要和要使用词向量的任务相似，并且越大越好，论文中实验说明语料比训练词向量的模型更加的重要，所以要尽量收集大的且与任务相关的语料来训练词向量；</li>
<li>语料小（小于一亿词，约 500MB 的文本文件）的时候用 Skip-gram 模型，语料大的时候用 CBOW 模型；</li>
<li>设置迭代次数为三五十次，维度至少选 50，常见的词向量的维度为256、512以及处理非常大的词表的时候的1024维；</li>
</ol>
<p>通过下面命令来执行Python文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">python word2vec_model.py seg_filename model_name word2vec.vector</span></pre></td></tr></table></figure>

<ol>
<li>word2vec_model.py：存放训练代码的Python文件；</li>
<li>seg_filename：分好词的训练语料；</li>
<li>model_name：训练好的模型的名称；</li>
<li>word2vec.vector：得到的词向量；</li>
</ol>
<p>对于本例来说：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">python word2vec_model.py wiki_jian_zh_seg<span class="number">-189.5</span>.txt wiki_zh_jian_text.model wiki_zh_jian_text.vector</span></pre></td></tr></table></figure>

<h2 id="3-测试模型"><a href="#3-测试模型" class="headerlink" title="3.测试模型"></a><strong>3.测试模型</strong></h2><p>有了词向量我们就可以使用词向量来做一些自然语言处理的任务了。那在这之前，我们需要测试一个模型是否训练成功。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">from gensim.models import Word2Vec</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">en_wiki_word2vec_model &#x3D; Word2Vec.load(&#39;wiki_zh_jian_text.model&#39;)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">testwords &#x3D; [&#39;金融&#39;,&#39;上&#39;,&#39;股票&#39;,&#39;跌&#39;,&#39;经济&#39;]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">for i in range(5):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">    res &#x3D; en_wiki_word2vec_model.most_similar(testwords[i])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">    print (testwords[i])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    print (res)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">&#39;&#39;&#39;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">result:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">    金融</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">        [(&#39;金融业&#39;, 0.7712020874023438), (&#39;房地产&#39;, 0.7530461549758911), (&#39;银行业&#39;, 0.7478024959564209), (&#39;保险业&#39;, 0.7240537405014038), (&#39;金融机构&#39;, 0.7114974856376648), (&#39;投资银行&#39;, 0.7104595899581909), (&#39;证券&#39;, 0.7046274542808533), (&#39;信贷&#39;, 0.7021963596343994), (&#39;金融服务&#39;, 0.6956385374069214), (&#39;公共事业&#39;, 0.6882480382919312)]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">    上</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">        [(&#39;之上&#39;, 0.5678470134735107), (&#39;上以&#39;, 0.4623713493347168), (&#39;上面&#39;, 0.4558977782726288), (&#39;上用&#39;, 0.42831096053123474), (&#39;水性&#39;, 0.4084252119064331), (&#39;上会&#39;, 0.3999699354171753), (&#39;方面&#39;, 0.3975197672843933), (&#39;上要&#39;, 0.3963406980037689), (&#39;上仅&#39;, 0.3950901925563812), (&#39;面上&#39;, 0.38935011625289917)]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">    股票</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">        [(&#39;期货&#39;, 0.7636638879776001), (&#39;债券&#39;, 0.7634198069572449), (&#39;外汇&#39;, 0.7477541565895081), (&#39;获利&#39;, 0.7359930276870728), (&#39;期权&#39;, 0.7332447171211243), (&#39;A股&#39;, 0.7319167852401733), (&#39;存款&#39;, 0.7306094765663147), (&#39;普通股&#39;, 0.7264690399169922), (&#39;不动产&#39;, 0.724310040473938), (&#39;证券&#39;, 0.7240179777145386)]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">    跌</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">        [(&#39;滑落&#39;, 0.70113605260849), (&#39;回落&#39;, 0.6962391138076782), (&#39;涨&#39;, 0.6842378377914429), (&#39;季尾&#39;, 0.6791133284568787), (&#39;攀升&#39;, 0.6673789620399475), (&#39;急跌&#39;, 0.6652034521102905), (&#39;跌落&#39;, 0.6540493965148926), (&#39;飙升&#39;, 0.6493663787841797), (&#39;下跌&#39;, 0.6452913284301758), (&#39;回升&#39;, 0.6349585652351379)]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">    经济</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">        [(&#39;工商业&#39;, 0.631495475769043), (&#39;国民经济&#39;, 0.6289297342300415), (&#39;农业&#39;, 0.6132777333259583), (&#39;生产力&#39;, 0.6094485521316528), (&#39;金融&#39;, 0.5886996984481812), (&#39;市场经济&#39;, 0.5880722403526306), (&#39;旅游业&#39;, 0.585972011089325), (&#39;对外贸易&#39;, 0.575571596622467), (&#39;经济繁荣&#39;, 0.5738641023635864), (&#39;金融业&#39;, 0.5717495083808899)]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">&#39;&#39;&#39;</span></pre></td></tr></table></figure>
    </div>
    
        <hr class="fhr">
        <div id="vcomments"></div>
    
</div>
    <div class="footer" id="footer">
    <p>Copyright © 2020 <a class="flink" href="https://hexo.io" target="_blank" rel="noopener">Hexo</a>-<a class="flink" href="https://github.com/sanjinhub/hexo-theme-geek" target="_blank" rel="noopener">Geek</a>.
        <label class="el-switch el-switch-green el-switch-sm" style="vertical-align: sub;">
            <input type="checkbox" name="switch" id="update_style">
            <span class="el-switch-style"></span>
        </label>
<!--         <script type="text/javascript">
        var cnzz_protocol = (("https:" == document.location.protocol) ? "https://" : "http://");
        document.write(unescape("%3Cspan id='cnzz_stat_icon_1278548644'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/stat.php%3Fid%3D1278548644%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
        </script> -->
    </p>
</div>
<input type="hidden" id="web_style" value="black">
<input type="hidden" id="valine_appid" value="CmCti21ooOOIzFOhEyFkFvR0-gzGzoHsz">
<input type="hidden" id="valine_appKey" value="FqiyUqbg7McKN2eG0MCewupf">

<script src="/libs/jquery.min.js"></script>


<script src="/libs/highlight/highlight.pack.js"></script>

<script src='//cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js'></script>

<script src="/js/js.js"></script>

<style type="text/css">
.v * {
    color: #698fca;
}

.v .vlist .vcard .vhead .vsys {
    color: #3a3e4a;
}

.v .vlist .vcard .vh .vmeta .vat {
    color: #638fd5;
}

.v .vlist .vcard .vhead .vnick {
    color: #6ba1ff;
}

.v a {
    color: #8696b1;
}

.v .vlist .vcard .vhead .vnick:hover {
    color: #669bfc;
}
</style>
</body>

</html>