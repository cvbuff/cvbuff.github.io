<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <title>
        NinetyOne&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/libs/highlight/styles/monokai-sublime.css">

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.1.0"></head>

<body id="bodyx">
    <div class="hd posts">
    <a href="/index.html"><i class="fa fa-reply replay-btn" aria-hidden="true"></i></a>
    <div class="post-title">
        <p>
            使用自己的语料训练word2vec模型
        </p>
        <hr>
    </div>
    <div class="post-content">
        <h4 id="使用自己的语料训练word2vec模型"><a href="#使用自己的语料训练word2vec模型" class="headerlink" title="使用自己的语料训练word2vec模型"></a><strong>使用自己的语料训练word2vec模型</strong></h4><h5 id="一、准备环境和语料："><a href="#一、准备环境和语料：" class="headerlink" title="一、准备环境和语料："></a>一、准备环境和语料：</h5><p>新闻20w+篇（格式：<code>标题</code>。<code>正文</code>） </p>
<p>【新闻可以自己从各大新闻网站爬取，也可以下载开源的新闻数据集，如 </p>
<ul>
<li><a href="http://www.sogou.com/labs/resource/t.php" target="_blank" rel="noopener">互联网语料库(SogouT)</a></li>
<li><a href="http://thuctc.thunlp.org/" target="_blank" rel="noopener">中文文本分类数据集THUCNews</a></li>
<li><a href="http://www.datatang.com/data/11968" target="_blank" rel="noopener">李荣陆英文文本分类语料</a></li>
<li><a href="http://www.datatang.com/data/11970" target="_blank" rel="noopener">谭松波中文文本分类语料</a></li>
<li>等</li>
<li><a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">结巴分词</a> </li>
<li><a href="https://radimrehurek.com/gensim/models/word2vec.html" target="_blank" rel="noopener">word2vec</a></li>
</ul>
<a id="more"></a>

<h5 id="二、分词"><a href="#二、分词" class="headerlink" title="二、分词"></a>二、分词</h5><p>先对新闻文本进行分词，使用的是结巴分词工具，将分词后的文本保存在<code>seg201708.txt</code>，以备后期使用。</p>
<blockquote>
<p>   安装jieba工具包：pip install jieba </p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载自己的自己的金融词库</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">jieba.load_userdict(<span class="string">"financialWords.txt"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">with</span> io.open(<span class="string">'news201708.txt'</span>,<span class="string">'r'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> content:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> content:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">            seg_list = jieba.cut(line)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line"><span class="comment">#           print '/'.join(seg_list)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">            <span class="keyword">with</span> io.open(<span class="string">'seg201708.txt'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> output:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">                output.write(<span class="string">' '</span>.join(seg_list))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">    main()</span></pre></td></tr></table></figure>



<h5 id="三、训练word2vec模型"><a href="#三、训练word2vec模型" class="headerlink" title="三、训练word2vec模型"></a>三、训练word2vec模型</h5><p>使用python的gensim包进行训练。</p>
<blockquote>
<p>   安装gemsim包：pip install gemsim </p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> word2vec</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">    num_features = <span class="number">300</span>    <span class="comment"># Word vector dimensionality</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">    min_word_count = <span class="number">10</span>   <span class="comment"># Minimum word count</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">    num_workers = <span class="number">16</span>       <span class="comment"># Number of threads to run in parallel</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">    context = <span class="number">10</span>          <span class="comment"># Context window size</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    downsampling = <span class="number">1e-3</span>   <span class="comment"># Downsample setting for frequent words</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">    sentences = word2vec.Text8Corpus(<span class="string">"seg201708.txt"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">    </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">    model = word2vec.Word2Vec(sentences, workers=num_workers, \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">            size=num_features, min_count = min_word_count, \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">            window = context, sg = <span class="number">1</span>, sample = downsampling)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">    model.init_sims(replace=<span class="literal">True</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">    <span class="comment"># 保存模型，供日後使用</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">    model.save(<span class="string">"model201708"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">    <span class="comment"># 可以在加载模型之后使用另外的句子来进一步训练模型</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">    <span class="comment"># model = gensim.models.Word2Vec.load('/tmp/mymodel')</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">    <span class="comment"># model.train(more_sentences)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line">    main()</span></pre></td></tr></table></figure>

<ul>
<li>参数说明</li>
</ul>
<blockquote>
</blockquote>
<ul>
<li>sentences：可以是一个·ist，对于大语料集，建议使用BrownCorpus,Text8Corpus或ineSentence构建。</li>
<li>sg： 用于设置训练算法，默认为0，对应CBOW算法；sg=1则采用skip-gram算法。</li>
<li>size：是指特征向量的维度，默认为100。大的size需要更多的训练数据,但是效果会更好. 推荐值为几十到几百。</li>
<li>window：表示当前词与预测词在一个句子中的最大距离是多少</li>
<li>alpha: 是学习速率</li>
<li>seed：用于随机数发生器。与初始化词向量有关。</li>
<li>min_count: 可以对字典做截断. 词频少于min_count次数的单词会被丢弃掉, 默认值为5</li>
<li>max_vocab_size: 设置词向量构建期间的RAM限制。如果所有独立单词个数超过这个，则就消除掉其中最不频繁的一个。每一千万个单词需要大约1GB的RAM。设置成None则没有限制。</li>
<li>sample: 高频词汇的随机降采样的配置阈值，默认为1e-3，范围是(0,1e-5)</li>
<li>workers参数控制训练的并行数。</li>
<li>hs: 如果为1则会采用hierarchica·softmax技巧。如果设置为0（defau·t），则negative sampling会被使用。</li>
<li>negative: 如果&gt;0,则会采用negativesamp·ing，用于设置多少个noise words</li>
<li>cbow_mean: 如果为0，则采用上下文词向量的和，如果为1（defau·t）则采用均值。只有使用CBOW的时候才起作用。</li>
<li>hashfxn： hash函数来初始化权重。默认使用python的hash函数</li>
<li>iter： 迭代次数，默认为5</li>
<li>trim_rule： 用于设置词汇表的整理规则，指定那些单词要留下，哪些要被删除。可以设置为None（min_count会被使用）或者一个接受()并返回RU·E_DISCARD,uti·s.RU·E_KEEP或者uti·s.RU·E_DEFAU·T的</li>
<li>sorted_vocab： 如果为1（defau·t），则在分配word index 的时候会先对单词基于频率降序排序。</li>
<li>batch_words：每一批的传递给线程的单词的数量，默认为10000</li>
</ul>
<h5 id="四、word2vec应用"><a href="#四、word2vec应用" class="headerlink" title="四、word2vec应用"></a>四、word2vec应用</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">model = Word2Vec.load(<span class="string">'model201708'</span>)      <span class="comment">#模型讀取方式</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">model.most_similar(positive=[<span class="string">'woman'</span>, <span class="string">'king'</span>], negative=[<span class="string">'man'</span>]) <span class="comment">#根据给定的条件推断相似词</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">model.doesnt_match(<span class="string">"breakfast cereal dinner lunch"</span>.split()) <span class="comment">#寻找离群词</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">model.similarity(<span class="string">'woman'</span>, <span class="string">'man'</span>) <span class="comment">#计算两个单词的相似度</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">model[<span class="string">'computer'</span>] <span class="comment">#获取单词的词向量</span></span></pre></td></tr></table></figure>
    </div>
    
        <hr class="fhr">
        <div id="vcomments"></div>
    
</div>
    <div class="footer" id="footer">
    <p>Copyright © 2020 <a class="flink" href="https://hexo.io" target="_blank" rel="noopener">Hexo</a>-<a class="flink" href="https://github.com/sanjinhub/hexo-theme-geek" target="_blank" rel="noopener">Geek</a>.
        <label class="el-switch el-switch-green el-switch-sm" style="vertical-align: sub;">
            <input type="checkbox" name="switch" id="update_style">
            <span class="el-switch-style"></span>
        </label>
<!--         <script type="text/javascript">
        var cnzz_protocol = (("https:" == document.location.protocol) ? "https://" : "http://");
        document.write(unescape("%3Cspan id='cnzz_stat_icon_1278548644'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/stat.php%3Fid%3D1278548644%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
        </script> -->
    </p>
</div>
<input type="hidden" id="web_style" value="black">
<input type="hidden" id="valine_appid" value="CmCti21ooOOIzFOhEyFkFvR0-gzGzoHsz">
<input type="hidden" id="valine_appKey" value="FqiyUqbg7McKN2eG0MCewupf">

<script src="/libs/jquery.min.js"></script>


<script src="/libs/highlight/highlight.pack.js"></script>

<script src='//cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js'></script>

<script src="/js/js.js"></script>

<style type="text/css">
.v * {
    color: #698fca;
}

.v .vlist .vcard .vhead .vsys {
    color: #3a3e4a;
}

.v .vlist .vcard .vh .vmeta .vat {
    color: #638fd5;
}

.v .vlist .vcard .vhead .vnick {
    color: #6ba1ff;
}

.v a {
    color: #8696b1;
}

.v .vlist .vcard .vhead .vnick:hover {
    color: #669bfc;
}
</style>
</body>

</html>